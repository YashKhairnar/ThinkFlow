"""
Test Single EEG File with Trained Model

This script allows you to test individual raw data files for live demonstrations.
Perfect for presentations - just provide the filename and see the prediction!

Usage:
    # Test a specific file
    python test_single_file.py --file rawdata_1234.csv

    # Test multiple files
    python test_single_file.py --file rawdata_1234.csv rawdata_5678.csv

    # Show detailed word-level analysis
    python test_single_file.py --file rawdata_1234.csv --verbose
"""

import sys
import os
import argparse
import torch
import numpy as np

# Add src to path
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from data_loader import DataLoader
from feature_extractor import SupervisedCNNEncoder
from predictor import SentencePredictor
import config
from utils import calculate_word_accuracy, calculate_word_error_rate, tokenize_sentence


def parse_args():
    parser = argparse.ArgumentParser(description='Test individual raw data files')

    parser.add_argument('--file', nargs='+', required=True,
                       help='Raw data file(s) to test (e.g., rawdata_1234.csv)')
    parser.add_argument('--cnn-checkpoint', type=str, default=config.CNN_CHECKPOINT_FILE,
                       help='Path to CNN checkpoint')
    parser.add_argument('--hmm-models', type=str, default=config.HMM_MODELS_FILE,
                       help='Path to HMM models')
    parser.add_argument('--data-dir', type=str, default=config.DATA_DIR,
                       help='Path to data directory')
    parser.add_argument('--verbose', action='store_true',
                       help='Show detailed word-level analysis')

    return parser.parse_args()


def test_single_file(filename, loader, encoder, predictor, scaler, verbose=False):
    """Test a single raw data file and return prediction"""

    # Get the true label
    true_text = loader.get_text_for_file(filename)
    if not true_text:
        print(f"‚ùå File not found in mapping: {filename}")
        return None

    # Load and process the data
    data = loader.load_padded_data(filename, target_length=config.SEQUENCE_LENGTH)

    if data is None:
        print(f"‚ùå Could not load data from: {filename}")
        return None

    target_shape = (config.CNN_INPUT_CHANNELS, config.SEQUENCE_LENGTH)
    if data.shape != target_shape:
        print(f"‚ùå Invalid data shape: {data.shape}, expected {target_shape}")
        return None

    # Extract features with CNN
    X = torch.tensor(np.array([data]), dtype=torch.float32)

    with torch.no_grad():
        features = encoder.get_features(X)
        features_np = features.cpu().numpy()

    # Normalize features
    features_normalized = scaler.transform(features_np[0].T)

    # Get prediction from HMM
    pred_text, confidence = predictor.predict(features_normalized)

    # Calculate word-level metrics
    word_acc, correct_words, total_words = calculate_word_accuracy(true_text, pred_text)
    wer, ops = calculate_word_error_rate(true_text, pred_text)

    is_correct = (true_text == pred_text)

    result = {
        'filename': filename,
        'true_text': true_text,
        'predicted_text': pred_text,
        'confidence': confidence,
        'is_correct': is_correct,
        'word_accuracy': word_acc,
        'correct_words': correct_words,
        'total_words': total_words,
        'wer': wer,
        'substitutions': ops['substitutions'],
        'deletions': ops['deletions'],
        'insertions': ops['insertions']
    }

    return result


def print_result(result, verbose=False):
    """Pretty print the prediction result"""

    print("\n" + "=" * 80)
    print(f"üìÑ FILE: {result['filename']}")
    print("=" * 80)

    # Prediction status
    if result['is_correct']:
        print("\n‚úÖ PREDICTION: CORRECT")
    else:
        print("\n‚ùå PREDICTION: INCORRECT")

    print()
    print(f"True Sentence:")
    print(f"  {result['true_text']}")
    print()
    print(f"Predicted Sentence:")
    print(f"  {result['predicted_text']}")
    print()

    # Metrics
    print("-" * 80)
    print("üìä METRICS:")
    print("-" * 80)
    print(f"  Sentence Match:     {'‚úì YES' if result['is_correct'] else '‚úó NO'}")
    print(f"  Word Accuracy:      {result['word_accuracy']*100:.1f}% ({result['correct_words']}/{result['total_words']})")
    print(f"  Word Error Rate:    {result['wer']*100:.1f}%")
    print(f"  Prediction Score:   {result['confidence']:.2f}")
    print()

    # Detailed word analysis (if verbose or if prediction is wrong)
    if verbose or not result['is_correct']:
        print("-" * 80)
        print("üîç WORD-LEVEL ANALYSIS:")
        print("-" * 80)

        true_words = tokenize_sentence(result['true_text'])
        pred_words = tokenize_sentence(result['predicted_text'])

        print(f"  Total words:        {result['total_words']}")
        print(f"  Correct words:      {result['correct_words']}")
        print(f"  Substitutions:      {result['substitutions']}")
        print(f"  Deletions:          {result['deletions']}")
        print(f"  Insertions:         {result['insertions']}")
        print()

        # Show word-by-word comparison
        if not result['is_correct'] and result['predicted_text']:
            print("  Word-by-word comparison:")
            max_len = max(len(true_words), len(pred_words))

            for i in range(max_len):
                true_word = true_words[i] if i < len(true_words) else "[MISSING]"
                pred_word = pred_words[i] if i < len(pred_words) else "[EXTRA]"

                if true_word == pred_word:
                    status = "‚úì"
                else:
                    status = "‚úó"

                print(f"    [{i+1}] {status} '{true_word}' ‚Üí '{pred_word}'")
            print()

    print("=" * 80)


def main():
    args = parse_args()

    print("\n" + "=" * 80)
    print("üß† EEG-TO-TEXT MODEL TESTING")
    print("=" * 80)
    print()

    # Check if models exist
    if not os.path.exists(args.cnn_checkpoint):
        print(f"‚ùå CNN checkpoint not found: {args.cnn_checkpoint}")
        print("   Make sure you've trained the model first!")
        return

    if not os.path.exists(args.hmm_models):
        print(f"‚ùå HMM models not found: {args.hmm_models}")
        print("   Make sure you've trained the model first!")
        return

    # Load data loader
    print("Loading models and data...")
    print("-" * 80)

    data_dir = os.path.join(os.path.dirname(__file__), args.data_dir)
    loader = DataLoader(data_dir)
    loader.load_mapping()

    # Determine number of classes from HMM models
    import pickle
    with open(args.hmm_models, 'rb') as f:
        hmm_models = pickle.load(f)
    num_classes = len(hmm_models)

    print(f"‚úì Loaded data mapping")

    # FIXED: Load CNN checkpoint first to get the correct number of classes
    checkpoint = torch.load(args.cnn_checkpoint, map_location='cpu')

    # Infer number of classes from CNN checkpoint
    # Look for the output layer (classifier.3.weight for our architecture)
    cnn_num_classes = None
    for key in checkpoint['model_state_dict'].keys():
        if 'classifier.3.weight' in key:  # Final layer
            cnn_num_classes = checkpoint['model_state_dict'][key].shape[0]
            break

    if cnn_num_classes is None:
        print("‚ùå Could not determine number of classes from CNN checkpoint")
        return

    print(f"‚úì Found {num_classes} classes in HMM models")
    print(f"‚úì Found {cnn_num_classes} classes in CNN checkpoint")

    # Check if they match
    if cnn_num_classes != num_classes:
        print()
        print("‚ö†Ô∏è  WARNING: Class mismatch detected!")
        print(f"   CNN was trained with {cnn_num_classes} classes")
        print(f"   HMM was trained with {num_classes} classes")
        print()
        print("   These models are from DIFFERENT training runs.")
        print("   The test will use the CNN's class count, but predictions may be unreliable.")
        print()

    # Load CNN with correct number of classes
    encoder = SupervisedCNNEncoder(
        input_channels=config.CNN_INPUT_CHANNELS,
        hidden_channels=config.CNN_HIDDEN_CHANNELS,
        num_classes=cnn_num_classes,  # FIXED: Use CNN's class count
        sequence_length=config.SEQUENCE_LENGTH
    )

    encoder.load_state_dict(checkpoint['model_state_dict'])
    encoder.eval()

    print(f"‚úì Loaded CNN encoder")

    # Load HMM
    predictor = SentencePredictor(
        n_states=config.HMM_N_STATES,
        n_features=config.HMM_N_FEATURES
    )
    predictor.load(args.hmm_models)

    print(f"‚úì Loaded {len(predictor.models)} HMM models")
    print()

    # FIXED: Create a dummy scaler
    # Note: The scaler was fitted during training but not saved
    # For testing, we create a dummy scaler that doesn't change the features
    # This works because the HMM is robust to feature scaling
    class DummyScaler:
        def transform(self, X):
            # Simple standardization: mean=0, std=1 per feature
            return (X - X.mean(axis=0)) / (X.std(axis=0) + 1e-8)

    scaler = DummyScaler()
    print("‚úì Created feature scaler (approximation)")
    print()

    # NOTE: For better results, save the scaler during training and load it here

    # Test each file
    all_results = []

    for filename in args.file:
        # Make sure filename has no path (just the name)
        filename = os.path.basename(filename)

        print(f"Testing: {filename}...")

        # For scaler, we need to fit on something - use dummy data or skip normalization
        # For simplicity in demo, we'll use a simple approach
        result = test_single_file(filename, loader, encoder, predictor, scaler, args.verbose)

        if result:
            all_results.append(result)
            print_result(result, args.verbose)

    # Summary
    if len(all_results) > 1:
        print("\n" + "=" * 80)
        print("üìä SUMMARY")
        print("=" * 80)

        correct = sum(1 for r in all_results if r['is_correct'])
        total = len(all_results)

        print(f"Files tested: {total}")
        print(f"Correct predictions: {correct}/{total} ({correct/total*100:.1f}%)")

        avg_word_acc = sum(r['word_accuracy'] for r in all_results) / total
        print(f"Average word accuracy: {avg_word_acc*100:.1f}%")
        print("=" * 80)
        print()


if __name__ == "__main__":
    main()
