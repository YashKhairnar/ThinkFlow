{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHs3WPn3fho9",
        "outputId": "7582d56d-2dd5-4251-941a-c79d21aa85f1"
      },
      "id": "tHs3WPn3fho9",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK5psndO1GgW",
        "outputId": "0c9fa44f-9f8b-410c-9c62-596ddf142e4d"
      },
      "id": "EK5psndO1GgW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboard\n",
        "import gensim.downloader as api\n",
        "import os\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from pathlib import Path\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "metadata": {
        "id": "csPOMsdw0v4_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3daa1d4-fc1b-4a8d-f4c8-3d0fe99586db"
      },
      "id": "csPOMsdw0v4_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (2.20.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard) (3.3.6)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboard) (25.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from tensorboard) (12.0.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (6.33.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (75.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.1.4)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio>=1.48.2->tensorboard) (4.15.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "Id5zrPc4zDNF"
      },
      "id": "Id5zrPc4zDNF"
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomEEGDataset(Dataset):\n",
        "    def __init__(self, sentence_mapping, eeg_path, pad_len=5500, dtype=torch.float32):\n",
        "        self.records = pd.read_csv(sentence_mapping)\n",
        "        self.records = self.records.reset_index(drop=True)\n",
        "        self.eeg_path = Path(eeg_path)\n",
        "        self.pad_len = int(pad_len)\n",
        "        self.dtype = dtype\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.records)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        row = self.records.iloc[idx]\n",
        "        uuid = row[\"UniqueID\"]\n",
        "        sentence = row[\"Content\"]\n",
        "\n",
        "        eeg = self._load_and_pad_eeg(uuid)  # [105, T] -> [105, pad_len]\n",
        "        # Return tensors without batch dimension; DataLoader will stack them\n",
        "        return {\n",
        "            \"uuid\": uuid,\n",
        "            \"sentence\": sentence,        # stays as string; DataLoader will make a list of strings\n",
        "            \"eeg\": eeg                   # torch.FloatTensor [105, pad_len]\n",
        "        }\n",
        "\n",
        "    def _load_and_pad_eeg(self, uuid: str) -> torch.Tensor:\n",
        "        path = self.eeg_path / f\"{uuid}.csv\"\n",
        "        if not path.exists():\n",
        "            raise FileNotFoundError(f\"EEG file not found: {path}\")\n",
        "\n",
        "        # Expect shape [channels=105, timesteps]; adjust if your CSV is transposed\n",
        "        df = pd.read_csv(path)\n",
        "        arr = df.values.astype(np.float32)\n",
        "\n",
        "        # If CSV is [T, 105] instead of [105, T], transpose:\n",
        "        if arr.shape[0] == 5500 and arr.shape[1] == 105:  # heuristic; change to your rule\n",
        "            arr = arr.T\n",
        "\n",
        "        # Pad or crop to pad_len along time axis (axis=1)\n",
        "        c, t = arr.shape\n",
        "        if c != 105:\n",
        "            raise ValueError(f\"Expected 105 channels, got {c} in {path}\")\n",
        "\n",
        "        if t < self.pad_len:\n",
        "            pad = np.zeros((c, self.pad_len - t), dtype=np.float32)\n",
        "            arr = np.concatenate([arr, pad], axis=1)\n",
        "        elif t > self.pad_len:\n",
        "            arr = arr[:, :self.pad_len]\n",
        "\n",
        "        return torch.from_numpy(arr).to(self.dtype)  # [105, pad_len]\n"
      ],
      "metadata": {
        "id": "S2OItP_NZs9b"
      },
      "id": "S2OItP_NZs9b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "28a526fa",
      "metadata": {
        "id": "28a526fa"
      },
      "source": [
        "# ENCODER - EEG to CODEX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a20d751",
      "metadata": {
        "id": "1a20d751"
      },
      "outputs": [],
      "source": [
        "class ConvolutionModel(nn.Module):\n",
        "    '''\n",
        "    Input : single sentence EEG raw input of (105 channels, 5500 timestamps)\n",
        "    Output : single sentence of 57 features of 512 dimensions embedding each\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.convolutional_model = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=105, kernel_size=10, out_channels=64, stride=3),\n",
        "            nn.Conv1d(in_channels=64,  kernel_size=3,  out_channels=128, stride=2),\n",
        "            nn.Conv1d(in_channels=128, kernel_size=3,  out_channels=256, stride=2),\n",
        "            nn.Conv1d(in_channels=256, kernel_size=3,  out_channels=512, stride=2),\n",
        "            nn.Conv1d(in_channels=512, kernel_size=2,  out_channels=512, stride=2),\n",
        "            nn.Conv1d(in_channels=512, kernel_size=2,  out_channels=512, stride=2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input shape expected: [batch_size, channels, timestamps]\n",
        "        op = self.convolutional_model(x)\n",
        "        # Output shape is [batch_size, d_model, num_tokens] -> transpose to [batch_size, num_tokens, d_model]\n",
        "        return op.permute(0, 2, 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Single-head scaled dot-product attention using nn.Linear layers.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, d_k):\n",
        "        super().__init__()\n",
        "        self.d_k = d_k\n",
        "        self.W_Q = nn.Linear(d_model, d_k, bias=False)\n",
        "        self.W_K = nn.Linear(d_model, d_k, bias=False)\n",
        "        self.W_V = nn.Linear(d_model, d_k, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        Q = self.W_Q(x)\n",
        "        K = self.W_K(x)\n",
        "        V = self.W_V(x)\n",
        "\n",
        "        scores = (Q @ K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "        attn_weights = F.softmax(scores, dim=-1)\n",
        "        output = attn_weights @ V\n",
        "        return output"
      ],
      "metadata": {
        "id": "ka_3SUR2y1q1"
      },
      "id": "ka_3SUR2y1q1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttentionBlock(nn.Module):\n",
        "    def __init__(self, d_model, heads=8):\n",
        "        super().__init__()\n",
        "        self.heads = heads\n",
        "        self.d_model = d_model\n",
        "        # d_k is the dimension of each head. Must be divisible by d_model\n",
        "        self.d_k = d_model // heads\n",
        "\n",
        "        # Use nn.ModuleList to register attention blocks with PyTorch\n",
        "        self.attentionBlocks = nn.ModuleList([AttentionBlock(d_model, self.d_k) for _ in range(self.heads)])\n",
        "\n",
        "        # Final linear layer to project concatenated heads back to d_model dimension\n",
        "        self.output_linear = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        head_outputs = []\n",
        "        for block in self.attentionBlocks:\n",
        "            # Assuming x is [batch_size, num_tokens, d_model]\n",
        "            out_h = block(x) # [batch_size, num_tokens, d_k]\n",
        "            head_outputs.append(out_h)\n",
        "\n",
        "        # Concatenate along the last dimension\n",
        "        total = torch.cat(head_outputs, dim=-1) # [batch_size, num_tokens, d_model]\n",
        "\n",
        "        # Apply final linear layer\n",
        "        output = self.output_linear(total)\n",
        "        return output"
      ],
      "metadata": {
        "id": "ZlM7JOISy71J"
      },
      "id": "ZlM7JOISy71J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, d_model=512, heads=8, beta=0.2):\n",
        "        super().__init__()\n",
        "        self.conv = ConvolutionModel()\n",
        "        self.mha = MultiHeadAttentionBlock(d_model=d_model, heads=heads)\n",
        "        self.codex = nn.Embedding(num_embeddings=2048, embedding_dim=512)\n",
        "        self.words = self.codex.weight  # codebook\n",
        "        self.beta = beta               # commitment weight\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: [batch_size, 105, 5500]\n",
        "\n",
        "        returns:\n",
        "            z_q_st: [batch_size, 57, 512]  (quantized, straight-through)\n",
        "            vq_loss: scalar (codebook + commitment terms)\n",
        "            indices: [batch_size, 57]  (chosen code indices)\n",
        "        \"\"\"\n",
        "        # conv_output: [batch_size, 57, 512]\n",
        "        conv_output = self.conv(x)\n",
        "\n",
        "        # attn_output: [batch_size, 57, 512] (this is z_c in VQ-VAE terms)\n",
        "        attn_output = self.mha(conv_output)\n",
        "\n",
        "        # --- vector quantization using your codex / words ---\n",
        "        B, L, D = attn_output.shape  # [B, 57, 512]\n",
        "\n",
        "        # make codebook shape [1, 2048, 512] so cdist works: [B, 57, 512] x [1, 2048, 512] -> [B, 57, 2048]\n",
        "        codebook = self.words.unsqueeze(0)  # [1, 2048, 512]\n",
        "        distances = torch.cdist(attn_output, codebook)  # [B, 57, 2048]\n",
        "\n",
        "        # indices of the least-distance codex word for each EEG feature\n",
        "        indices = torch.argmin(distances, dim=-1)  # [B, 57]\n",
        "\n",
        "        # quantized vectors via embedding lookup\n",
        "        z_q = self.codex(indices)  # [B, 57, 512]\n",
        "\n",
        "        # --- VQ codebook + commitment losses ---\n",
        "\n",
        "        # codebook loss: || sg[attn_output] - z_q ||^2  (update codex/words)\n",
        "        codebook_loss = F.mse_loss(z_q, attn_output.detach())\n",
        "\n",
        "        # commitment loss: || attn_output - sg[z_q] ||^2  (update encoder)\n",
        "        commitment_loss = F.mse_loss(attn_output, z_q.detach())\n",
        "\n",
        "        vq_loss = codebook_loss + self.beta * commitment_loss\n",
        "\n",
        "        # straight-through: forward uses z_q, grads go to attn_output\n",
        "        z_q_st = attn_output + (z_q - attn_output).detach()\n",
        "\n",
        "        return z_q_st, vq_loss, indices"
      ],
      "metadata": {
        "id": "F0XBlWuBy3-E"
      },
      "id": "F0XBlWuBy3-E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2a77a667",
      "metadata": {
        "id": "2a77a667"
      },
      "source": [
        "# DECODER - self reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "265e70ec",
      "metadata": {
        "id": "265e70ec"
      },
      "outputs": [],
      "source": [
        "class DeConvolutionModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Input  (to this block): [B, 512, 57]\n",
        "    Output (from this block): [B, 105, 5500]\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.deconv = nn.Sequential(\n",
        "            nn.ConvTranspose1d(in_channels=512, out_channels=512, kernel_size=2, stride=2),  # 57 -> 114\n",
        "            nn.ConvTranspose1d(in_channels=512, out_channels=512, kernel_size=2, stride=2),  # 114 -> 228\n",
        "            nn.ConvTranspose1d(in_channels=512, out_channels=256, kernel_size=3, stride=2),  # 228 -> 457\n",
        "            nn.ConvTranspose1d(in_channels=256, out_channels=128, kernel_size=3, stride=2),  # 457 -> 915\n",
        "            nn.ConvTranspose1d(in_channels=128, out_channels=64,  kernel_size=3, stride=2),  # 915 -> 1831\n",
        "            nn.ConvTranspose1d(in_channels=64,  out_channels=105, kernel_size=10, stride=3), # 1831 -> 5500\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.deconv(x)  # [B, 105, 5500]\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, d_model=512, heads=8):\n",
        "        super().__init__()\n",
        "        self.mha = MultiHeadAttentionBlock(d_model=d_model, heads=heads)  # keeps [B, 57, 512]\n",
        "        self.deconv = DeConvolutionModel()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, 57, 512]\n",
        "        attn_out = self.mha(x)                 # [B, 57, 512]\n",
        "        attn_out = attn_out.permute(0, 2, 1)   # -> [B, 512, 57]  (channels = 512, length = 57)\n",
        "        out = self.deconv(attn_out)            # -> [B, 105, 5500]\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2bef323",
      "metadata": {
        "id": "e2bef323"
      },
      "source": [
        "# WORD2VEC - converting sentences to embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e75671b",
      "metadata": {
        "id": "0e75671b"
      },
      "outputs": [],
      "source": [
        "class Word2VecModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.w2v = api.load('word2vec-google-news-300')\n",
        "        self.linear = nn.Linear(300, 512)\n",
        "        self.unk_vector = torch.zeros(300)  # vector for unknown words\n",
        "\n",
        "    def forward(self, sentence_tokens):\n",
        "      \"\"\"\n",
        "      sentence_tokens: list of tokens (strings)\n",
        "      returns: [num_words, 512] tensor\n",
        "      \"\"\"\n",
        "      device = self.linear.weight.device\n",
        "\n",
        "      vectors = []\n",
        "      for word in sentence_tokens:\n",
        "          if word in self.w2v:\n",
        "              vec = torch.tensor(self.w2v[word], dtype=torch.float32, device=device)\n",
        "          else:\n",
        "              vec = self.unk_vector.to(device)\n",
        "          vectors.append(vec)\n",
        "\n",
        "      emb = torch.stack(vectors)              # [num_words, 300]\n",
        "      enh_emb = self.linear(emb)              # [num_words, 512]\n",
        "\n",
        "      z_t_interpolated = F.interpolate(\n",
        "          enh_emb.transpose(0, 1).unsqueeze(0),  # [1, 512, num_words]\n",
        "          size=57,                               # Match EEG length\n",
        "          mode='linear',\n",
        "          align_corners=True\n",
        "      ).squeeze(0).transpose(0, 1)  # [57, 512]\n",
        "\n",
        "      return z_t_interpolated\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop"
      ],
      "metadata": {
        "id": "mpKq_FyP2r5j"
      },
      "id": "mpKq_FyP2r5j"
    },
    {
      "cell_type": "code",
      "source": [
        "def nt_xent_loss(out, target, temperature=0.07):\n",
        "  zq = F.normalize(out,dim=1)\n",
        "  zt = F.normalize(target,dim=1)\n",
        "\n",
        "  logits = zq @ zt.T / temperature #Build similarity matrix. Smaller τ → make similarities more “peaked” → harder classification → stronger gradients.\n",
        "\n",
        "  labels = torch.arange(logits.shape[0], device=logits.device)\n",
        "  #For row 0: the correct target index is 0 → wants softmax to choose column 0 and so on for all the rows\n",
        "\n",
        "  loss = F.cross_entropy(logits, labels)\n",
        "  return loss"
      ],
      "metadata": {
        "id": "voQjWeDCykW0"
      },
      "id": "voQjWeDCykW0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CKPT_DIR = \"/content/drive/MyDrive/EEG_dataset/NewCheckpoints\"  # or just \"checkpoints\"\n",
        "os.makedirs(CKPT_DIR, exist_ok=True)\n",
        "\n",
        "def save_checkpoint(epoch, encoder, decoder, w2v, optimizer,\n",
        "                    avg_total, avg_recon, avg_vq, avg_contrast,\n",
        "                    path):\n",
        "    state = {\n",
        "        \"epoch\": epoch,\n",
        "        \"encoder_state\": encoder.state_dict(),\n",
        "        \"decoder_state\": decoder.state_dict(),\n",
        "        \"w2v_state\": w2v.state_dict(),\n",
        "        \"optimizer_state\": optimizer.state_dict(),\n",
        "        \"avg_total\": avg_total,\n",
        "        \"avg_recon\": avg_recon,\n",
        "        \"avg_vq\": avg_vq,\n",
        "        \"avg_contrast\": avg_contrast,\n",
        "    }\n",
        "    torch.save(state, path)\n",
        "    print(f\"[Checkpoint] Saved to {path}\")\n",
        "\n",
        "\n",
        "\n",
        "def load_checkpoint(path, encoder, decoder, w2v, optimizer=None, map_location=\"cpu\"):\n",
        "    checkpoint = torch.load(path, map_location=map_location)\n",
        "\n",
        "    encoder.load_state_dict(checkpoint[\"encoder_state\"])\n",
        "    decoder.load_state_dict(checkpoint[\"decoder_state\"])\n",
        "    w2v.load_state_dict(checkpoint[\"w2v_state\"])\n",
        "\n",
        "    if optimizer is not None and \"optimizer_state\" in checkpoint:\n",
        "        optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
        "\n",
        "    epoch = checkpoint.get(\"epoch\", 0)\n",
        "    avg_total = checkpoint.get(\"avg_total\", None)\n",
        "    avg_recon = checkpoint.get(\"avg_recon\", None)\n",
        "    avg_vq = checkpoint.get(\"avg_vq\", None)\n",
        "    avg_contrast = checkpoint.get(\"avg_contrast\", None)\n",
        "\n",
        "    print(f\"[Checkpoint] Loaded from {path} (epoch {epoch})\")\n",
        "    return epoch, avg_total, avg_recon, avg_vq, avg_contrast\n"
      ],
      "metadata": {
        "id": "JMCgEDYho5mI"
      },
      "id": "JMCgEDYho5mI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(epoch_index):\n",
        "    ALPHA = 1.0   # weight for contrastive loss\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "    w2v.train()\n",
        "\n",
        "    running_total = 0.0\n",
        "    running_recon = 0.0\n",
        "    running_vq = 0.0\n",
        "    running_contrast = 0.0\n",
        "\n",
        "    for i, data in enumerate(dataloader):\n",
        "        sentences = data[\"sentence\"]          # list of B strings\n",
        "        eeg = data[\"eeg\"].to(device)          # [B, 105, 5500]\n",
        "\n",
        "        # 1) EEG -> encoder with VQ\n",
        "        z_q, vq_loss, indices = encoder(eeg)  # [B, 57, 512], scalar\n",
        "\n",
        "        # 2) EEG reconstruction\n",
        "        predictions = decoder(z_q)            # [B, 105, 5500]\n",
        "        reconstruction_loss = F.mse_loss(predictions, eeg)\n",
        "\n",
        "        # 3) Text embeddings (Word2Vec per sentence)\n",
        "        text_embeddings_list = [w2v(s.split()) for s in sentences]  # each [57, 512]\n",
        "        text_embeddings = torch.stack(text_embeddings_list, dim=0)  # [B, 57, 512]\n",
        "\n",
        "        # 4) Pool and contrastive loss\n",
        "        z_q_pooled = z_q.mean(dim=1)               # [B, 512]\n",
        "        text_pooled = text_embeddings.mean(dim=1)  # [B, 512]\n",
        "\n",
        "        contrastive_loss = nt_xent_loss(z_q_pooled, text_pooled)\n",
        "\n",
        "        # 5) Combine losses\n",
        "        L_wave = 0.5*reconstruction_loss + 0.5*vq_loss\n",
        "        loss = L_wave + ALPHA*contrastive_loss          # you can later scale terms\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_total += loss.item()\n",
        "        running_recon += reconstruction_loss.item()\n",
        "        running_vq += vq_loss.item()\n",
        "        running_contrast += contrastive_loss.item()\n",
        "\n",
        "    num_batches = len(dataloader)\n",
        "    avg_total = running_total / num_batches\n",
        "    avg_recon = running_recon / num_batches\n",
        "    avg_vq = running_vq / num_batches\n",
        "    avg_contrast = running_contrast / num_batches\n",
        "\n",
        "    return avg_total, avg_recon, avg_vq, avg_contrast\n"
      ],
      "metadata": {
        "id": "kvRwFxSI2rfe"
      },
      "id": "kvRwFxSI2rfe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_mapping = '/content/drive/MyDrive/EEG_dataset/dataset/sentence_mapping.csv'\n",
        "eeg_path = '/content/drive/MyDrive/EEG_dataset/dataset'\n",
        "\n",
        "# hyperparams\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50\n",
        "LR = 1e-3\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# models\n",
        "encoder = Encoder().to(device)\n",
        "decoder = Decoder().to(device)\n",
        "w2v = Word2VecModel().to(device)\n",
        "\n",
        "# dataset & dataloader\n",
        "dataset = CustomEEGDataset(\n",
        "    sentence_mapping=sentence_mapping,\n",
        "    eeg_path=eeg_path,\n",
        ")\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.Adam(\n",
        "    list(encoder.parameters()) +\n",
        "    list(decoder.parameters()) +\n",
        "    list(w2v.parameters()),\n",
        "    lr=LR\n",
        ")\n",
        "\n",
        "# --------- OPTIONAL: resume from an existing checkpoint ---------\n",
        "resume = False\n",
        "resume_path = \"/content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_26.pt\"\n",
        "\n",
        "start_epoch = 0\n",
        "if resume:\n",
        "    start_epoch, last_loss = load_checkpoint(\n",
        "        path=resume_path,\n",
        "        encoder=encoder,\n",
        "        decoder=decoder,\n",
        "        w2v=w2v,\n",
        "        optimizer=optimizer,\n",
        "    )\n",
        "    print(f\"Resuming from epoch {start_epoch} with loss = {last_loss:.4f}\")\n",
        "\n",
        "# --------- history dict to log losses for plotting ---------\n",
        "history = {\n",
        "    \"epoch\": [],\n",
        "    \"total\": [],\n",
        "    \"recon\": [],\n",
        "    \"vq\": [],\n",
        "    \"contrast\": [],\n",
        "}\n",
        "\n",
        "# --------- Training loop ---------\n",
        "for epoch in range(start_epoch + 1, EPOCHS):\n",
        "    avg_total, avg_recon, avg_vq, avg_contrast = train_one_epoch(epoch_index=epoch)\n",
        "\n",
        "    # save into history\n",
        "    history[\"epoch\"].append(epoch)\n",
        "    history[\"total\"].append(avg_total)\n",
        "    history[\"recon\"].append(avg_recon)\n",
        "    history[\"vq\"].append(avg_vq)\n",
        "    history[\"contrast\"].append(avg_contrast)\n",
        "\n",
        "    # console logging\n",
        "    print(\n",
        "        f\"Epoch [{epoch + 1}/{EPOCHS}] | \"\n",
        "        f\"total: {avg_total:.4f} | \"\n",
        "        f\"recon: {avg_recon:.4f} | \"\n",
        "        f\"vq: {avg_vq:.4f} | \"\n",
        "        f\"contrast: {avg_contrast:.4f}\"\n",
        "    )\n",
        "\n",
        "    # save checkpoint for this epoch\n",
        "    save_checkpoint(\n",
        "        epoch=epoch,\n",
        "        encoder=encoder,\n",
        "        decoder=decoder,\n",
        "        w2v=w2v,\n",
        "        optimizer=optimizer,\n",
        "        avg_total = avg_total,\n",
        "        avg_recon = avg_recon,\n",
        "        avg_vq = avg_vq,\n",
        "        avg_contrast = avg_contrast,\n",
        "        path=f\"/content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_{epoch}.pt\"\n",
        "    )\n",
        "\n",
        "# --------- after training: save the history so you can plot later ---------\n",
        "import pandas as pd\n",
        "\n",
        "log_path = \"/content/drive/MyDrive/EEG_dataset/NewCheckpoints/training_log.csv\"\n",
        "pd.DataFrame(history).to_csv(log_path, index=False)\n",
        "print(f\"Saved loss history to {log_path}\")\n"
      ],
      "metadata": {
        "id": "1QbwRojymQc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81c02d0d-bc75-4242-ac32-62a5187ab788"
      },
      "id": "1QbwRojymQc4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/50] | total: 11.8750 | recon: 13.4513 | vq: 3.3741 | contrast: 3.4623\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_1.pt\n",
            "Epoch [3/50] | total: 11.3614 | recon: 13.3610 | vq: 2.4890 | contrast: 3.4365\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_2.pt\n",
            "Epoch [4/50] | total: 84115.6715 | recon: 13.7103 | vq: 168210.7006 | contrast: 3.4662\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_3.pt\n",
            "Epoch [5/50] | total: 1549.0768 | recon: 13.7070 | vq: 3077.5331 | contrast: 3.4567\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_4.pt\n",
            "Epoch [6/50] | total: 476.0300 | recon: 13.7066 | vq: 931.4492 | contrast: 3.4521\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_5.pt\n",
            "Epoch [7/50] | total: 507.5391 | recon: 13.7010 | vq: 994.4593 | contrast: 3.4590\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_6.pt\n",
            "Epoch [8/50] | total: 592.0176 | recon: 13.6988 | vq: 1163.4094 | contrast: 3.4635\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_7.pt\n",
            "Epoch [9/50] | total: 208.0024 | recon: 13.7035 | vq: 395.4095 | contrast: 3.4459\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_8.pt\n",
            "Epoch [10/50] | total: 141.9942 | recon: 13.7005 | vq: 263.4105 | contrast: 3.4387\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_9.pt\n",
            "Epoch [11/50] | total: 105.6033 | recon: 13.6945 | vq: 190.6495 | contrast: 3.4313\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_10.pt\n",
            "Epoch [12/50] | total: 86.8724 | recon: 13.6841 | vq: 153.2050 | contrast: 3.4279\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_11.pt\n",
            "Epoch [13/50] | total: 72.7941 | recon: 13.6827 | vq: 125.0650 | contrast: 3.4203\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_12.pt\n",
            "Epoch [14/50] | total: 72.6302 | recon: 13.6629 | vq: 124.7435 | contrast: 3.4270\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_13.pt\n",
            "Epoch [15/50] | total: 985.9136 | recon: 13.7009 | vq: 1951.2506 | contrast: 3.4379\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_14.pt\n",
            "Epoch [16/50] | total: 56.9545 | recon: 13.6990 | vq: 93.3106 | contrast: 3.4497\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_15.pt\n",
            "Epoch [17/50] | total: 36.1942 | recon: 13.6946 | vq: 51.8337 | contrast: 3.4300\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_16.pt\n",
            "Epoch [18/50] | total: 35.3916 | recon: 13.6537 | vq: 50.2928 | contrast: 3.4183\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_17.pt\n",
            "Epoch [19/50] | total: 34.9350 | recon: 13.6441 | vq: 49.3803 | contrast: 3.4228\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_18.pt\n",
            "Epoch [20/50] | total: 36.5005 | recon: 13.6643 | vq: 52.4445 | contrast: 3.4461\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_19.pt\n",
            "Epoch [21/50] | total: 34.6432 | recon: 13.6286 | vq: 48.7953 | contrast: 3.4313\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_20.pt\n",
            "Epoch [22/50] | total: 38.5652 | recon: 13.6613 | vq: 56.5946 | contrast: 3.4373\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_21.pt\n",
            "Epoch [23/50] | total: 38.3386 | recon: 13.6591 | vq: 56.1485 | contrast: 3.4348\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_22.pt\n",
            "Epoch [24/50] | total: 51.4465 | recon: 13.6870 | vq: 82.3103 | contrast: 3.4478\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_23.pt\n",
            "Epoch [25/50] | total: 5644820775.8820 | recon: 4139.3646 | vq: 11289637711.3937 | contrast: 3.4476\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_24.pt\n",
            "Epoch [26/50] | total: 350330479472.0865 | recon: 560229.7487 | vq: 700660400316.1946 | contrast: 3.4630\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_25.pt\n",
            "Epoch [27/50] | total: 9900320283.6757 | recon: 321.4422 | vq: 19800640567.3514 | contrast: 3.4531\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_26.pt\n",
            "Epoch [28/50] | total: 4428633197.3189 | recon: 175.8946 | vq: 8857266394.6378 | contrast: 3.4440\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_27.pt\n",
            "Epoch [29/50] | total: 2717791708.0216 | recon: 124.5712 | vq: 5435583411.8919 | contrast: 3.4350\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_28.pt\n",
            "Epoch [30/50] | total: 1912511820.1081 | recon: 98.9579 | vq: 3825023636.0649 | contrast: 3.4288\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_29.pt\n",
            "Epoch [31/50] | total: 1421234838.1405 | recon: 82.2005 | vq: 2842469667.9784 | contrast: 3.4240\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_30.pt\n",
            "Epoch [32/50] | total: 1097405315.4595 | recon: 70.3023 | vq: 2194810583.8703 | contrast: 3.4232\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_31.pt\n",
            "Epoch [33/50] | total: 23545955448321.0391 | recon: 64.8342 | vq: 47091910896632.3906 | contrast: 3.4695\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_32.pt\n",
            "Epoch [34/50] | total: 172209977133.6649 | recon: 57.6312 | vq: 344419954267.3297 | contrast: 3.4730\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_33.pt\n",
            "Epoch [35/50] | total: 153183150279.2649 | recon: 52.2719 | vq: 306366300558.5297 | contrast: 3.4680\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_34.pt\n",
            "Epoch [36/50] | total: 58605519755.7622 | recon: 46.7838 | vq: 117211039511.5243 | contrast: 3.4594\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_35.pt\n",
            "Epoch [37/50] | total: 49912603177.5135 | recon: 42.7533 | vq: 99825206355.0270 | contrast: 3.4536\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_36.pt\n",
            "Epoch [38/50] | total: 45743955182.0108 | recon: 42.4028 | vq: 91487910364.0216 | contrast: 3.4565\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_37.pt\n",
            "Epoch [39/50] | total: 40609413728.8649 | recon: 37.7919 | vq: 81218827457.7297 | contrast: 3.4535\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_38.pt\n",
            "Epoch [40/50] | total: 30830828892.7135 | recon: 36.0104 | vq: 61661657785.4270 | contrast: 3.4531\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_39.pt\n",
            "Epoch [41/50] | total: 30178853971.0270 | recon: 46.3014 | vq: 60357707942.0541 | contrast: 3.4519\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_40.pt\n",
            "Epoch [42/50] | total: 27581441770933.2773 | recon: 36.4817 | vq: 55162883541866.5547 | contrast: 3.4521\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_41.pt\n",
            "Epoch [43/50] | total: 59680801149702.9219 | recon: 32.7723 | vq: 119361602299405.8438 | contrast: 3.4663\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_42.pt\n",
            "Epoch [44/50] | total: 774531378956.4541 | recon: 28.0139 | vq: 1549062757912.9082 | contrast: 3.4651\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_43.pt\n",
            "Epoch [45/50] | total: 444693217457.1243 | recon: 27.7283 | vq: 889386434914.2487 | contrast: 3.4628\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_44.pt\n",
            "Epoch [46/50] | total: 196400687624.3027 | recon: 58.6672 | vq: 392801375248.6054 | contrast: 3.4578\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_45.pt\n",
            "Epoch [47/50] | total: 334131831536.7784 | recon: 194.1208 | vq: 668263663073.5568 | contrast: 3.4545\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_46.pt\n",
            "Epoch [48/50] | total: 7435060176242.8545 | recon: 23.7800 | vq: 14870120352485.7090 | contrast: 3.4629\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_47.pt\n",
            "Epoch [49/50] | total: 147376703211.2433 | recon: 24.6464 | vq: 294753406422.4865 | contrast: 3.4626\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_48.pt\n",
            "Epoch [50/50] | total: 360115788716.9730 | recon: 51.5092 | vq: 720231577433.9459 | contrast: 3.4607\n",
            "[Checkpoint] Saved to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/epoch_49.pt\n",
            "Saved loss history to /content/drive/MyDrive/EEG_dataset/NewCheckpoints/training_log.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot the loss graph"
      ],
      "metadata": {
        "id": "M4vSTgfeevbB"
      },
      "id": "M4vSTgfeevbB"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "log_path = \"/content/drive/MyDrive/EEG_dataset/NewCheckpoints/training_log.csv\"\n",
        "df = pd.read_csv(log_path)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(df[\"epoch\"], df[\"total\"], label=\"total\")\n",
        "plt.plot(df[\"epoch\"], df[\"recon\"], label=\"recon\")\n",
        "plt.plot(df[\"epoch\"], df[\"vq\"], label=\"vq\")\n",
        "plt.plot(df[\"epoch\"], df[\"contrast\"], label=\"contrast\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Training losses\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KimrgAVceul6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "ba92dc00-d64e-4372-f539-87a00e202e54"
      },
      "id": "KimrgAVceul6",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V6E1",
      "machine_shape": "hm"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}